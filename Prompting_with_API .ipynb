{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Applied Generative AI\n",
        "Instructor: Prof. Dehghani\n",
        "Welcome to the Applied Generative AI course. In this course, we will explore the foundations and applications of Generative AI using tools like OpenAI's API. By the end of this session, you will:\n",
        "\n",
        "üü¢ Understand how to set up and connect to OpenAI's API.\n",
        "üåü Learn about the roles (System, Assistant, User) in prompt design.\n",
        "‚ú® Generate text, images, and vector embeddings programmatically.\n",
        "üîß Explore fine-tuning to customize AI models for specific tasks.\n",
        "Let‚Äôs get started with setting up the OpenAI API!"
      ],
      "metadata": {
        "id": "3S5eQNmwPUH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the OpenAI Python SDK\n",
        "# This library allows us to interact with OpenAI's API for text, images, and embeddings.\n",
        "!pip install openai==0.28"
      ],
      "metadata": {
        "id": "WNdB6dNqWG7L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efbf4e7a-2a37-4307-ad31-43fe137d2260"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (3.13.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (2026.1.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.22.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->openai==0.28) (4.15.0)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 2.16.0\n",
            "    Uninstalling openai-2.16.0:\n",
            "      Successfully uninstalled openai-2.16.0\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import openai\n",
        "\n",
        "# Retrieve the key from Colab secrets\n",
        "openai.api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Confirm the key was loaded (for debugging only; don‚Äôt print your real key in shared notebooks!)\n",
        "print(\"Key loaded:\", \"Yes\" if openai.api_key else \"No\")\n"
      ],
      "metadata": {
        "id": "IkCBK7FpWJ4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dd470ba-da54-40e0-dba9-a1945fb0e3fd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key loaded: Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ Prompt Playground: Understanding Roles\n",
        "In OpenAI's API, you interact with the model using roles, which define the flow of the conversation:\n",
        "\n",
        "‚û°Ô∏è System: Sets the behavior and tone of the assistant (e.g., \"You are a cheerful assistant.\").\n",
        "‚û°Ô∏è User: Represents the input or question from the user (e.g., \"What is AI?\").\n",
        "‚û°Ô∏è Assistant: Automatically generated responses based on the system and user inputs.\n",
        "üí° Why Roles Matter: Roles help control the assistant's personality and the quality of responses. For example:\n",
        "\n",
        "A system message like \"You are a strict teacher\" makes the assistant respond more formally.\n",
        "A system message like \"You are a friendly chatbot\" leads to casual responses.\n",
        "Let‚Äôs see how these roles work in the next cell!\n",
        "\n",
        "## Example 1: Without Assistant Role"
      ],
      "metadata": {
        "id": "Rtir4dZMPrc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])\n"
      ],
      "metadata": {
        "id": "YXvUTgLCWq4u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "282139ea-db4e-4623-fc16-212c45fff178"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of France is Paris.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 2: With Assistant Role"
      ],
      "metadata": {
        "id": "ytKbu3esTO5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Demonstrating roles in OpenAI's API with the assistant role\n",
        "\n",
        "# Define the conversation including a predefined assistant response\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a math tutor who explains problems step by step.\"},  # System role sets the behavior\n",
        "    {\"role\": \"user\", \"content\": \"Solve for x: 2x + 5 = 15\"},  # User question\n",
        "    {\"role\": \"assistant\", \"content\": \"To solve for x: \\n1. Subtract 5 from both sides: 2x = 10\\n2. Divide both sides by 2: x = 5\"}  # Predefined assistant response\n",
        "]\n",
        "\n",
        "# Send the conversation to the API\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-4\",  # Use the chosen model\n",
        "    messages=messages  # Pass the conversation\n",
        ")\n",
        "\n",
        "# Print the assistant's response\n",
        "print(\"Assistant's Response:\", response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "9pcHetiWWuM-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff25cdfd-34cd-4e4d-f34a-038eb479d5ad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant's Response: To solve for x: \n",
            "1. Subtract 5 from both sides: 2x = 10\n",
            "2. Divide both sides by 2: x = 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üßÆ Hands-On"
      ],
      "metadata": {
        "id": "BsL0AR6MTajz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ++++ Hands-On: Complete the Roles ++++\n",
        "\n",
        "# Define the conversation using the role structure\n",
        "messages = [\n",
        "    {\"role\": \"----\", \"content\": \"You are a math tutor who explains concepts clearly and step by step.\"},  # Complete the system role\n",
        "    {\"role\": \"----\", \"content\": \"How do you calculate the arithmetic mean of a set of numbers?\"},  # Complete the user role\n",
        "    {\"role\": \"----\", \"content\": \"To calculate the arithmetic mean:\\n\"\n",
        "                                \"1. Add all the numbers in the set.\\n\"\n",
        "                                \"2. Divide the sum by the number of numbers.\\n\\n\"\n",
        "                                \"For example, for 10, 20, and 30:\\n\"\n",
        "                                \"Mean = (10 + 20 + 30) / 3 = 60 / 3 = 20.\"\n",
        "                                }  # Optional predefined assistant response\n",
        "]\n",
        "\n",
        "# Uncomment the code below after completing the placeholders\n",
        "# response = openai.ChatCompletion.create(\n",
        "#     model=\"gpt-4\",  # Specify the model\n",
        "#     messages=messages  # Pass the completed conversation\n",
        "# )\n",
        "# print(\"Assistant's Response:\", response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "Bl5CCoC9TZ1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 1: Simple Q&A with System + User Roles\n",
        "üëâ Task:\n",
        "Write a prompt that asks the assistant to behave like a science teacher, then ask it a science-related question."
      ],
      "metadata": {
        "id": "bpTm-F37UIMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üß† Define your own roles and prompt below\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a science teacher who explains concepts clearly using simple, real-world examples suitable for beginners.\"\n",
        "    },\n",
        "    {\"role\": \"user\", \"content\": \"Ask your question here, 'Why does the sky appear blue during the day?\"}\n",
        "]\n",
        "\n",
        "# üß† Call the OpenAI API with your customized prompt\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "# üß† Print the model's response\n",
        "print(\"Assistant's Response:\", response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "_ZNQimnSUIpr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b54e51ad-f27e-4c97-d323-245abbfaa4f2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant's Response: The sky appears blue during the day because of a process called Rayleigh scattering. To break this down, let's use an example using sunlight and a glass of milk.\n",
            "\n",
            "Sunlight, like the light we see from the sun, is a mixture of all different colors of light, similar to how a glass of milk is a mixture of milk and water. When sunlight reaches Earth's atmosphere, it interacts with molecules in the air. This is similar to when you stir milk into water. When you stir, the milk spreads out in the water.\n",
            "\n",
            "The blue light waves are shorter and are scattered in all different directions much more than other colors like red or green because they have longer wavelengths. This is like when you stir the milk, and the tiny particles of milk spread out more than the larger ones.\n",
            "\n",
            "The end result is that when you look up at the sky, you mainly see the blue light because it gets scattered around the sky, and much of it reaches your eyes. In the case of our glass of milk, when you look at it, it appears a milky white color because the tiny particles of milk are well scattered throughout the water.\n",
            "\n",
            "So, in a similar way, our sky appears blue to us during a clear day because the blue light from the sun is scattered in all directions all around the sky more than other colors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úçÔ∏è Exercise 2: Give a prompt of your choice.\n",
        "üëâ Task:\n",
        "Now write your own custom prompt. Use any role, any question ‚Äî be creative!"
      ],
      "metadata": {
        "id": "bNOSyWlbUs82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with your own prompt idea!\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a career coach who gives clear, practical advice to students preparing for their first full-time job.\"},\n",
        "    {\"role\": \"user\", \"content\": \"How can I prepare effectively for behavioral interviews?\"}\n",
        "]\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "print(\"Assistant's Response:\", response['choices'][0]['message']['content'])\n"
      ],
      "metadata": {
        "id": "frrq5UkhU8Xj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b0ddb4a-6aa1-4cdc-d228-b58c0ea3cd72"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant's Response: Behavioral interviews are designed to understand how you react to specific situations in a work setting. The interviewer will likely be looking for information about your skills and abilities, as well as your personality and how you handle certain situations. Here are some tips on how you can prepare effectively:\n",
            "\n",
            "1. Understand how it works: In behavioral interviews, your potential employers will be looking for concrete examples of how you've dealt with certain situations or challenges in the past.\n",
            "\n",
            "2. Review the job description: Understanding the role you are applying for is vital in responding to behavioral interview questions. Identify key skills and traits and think of situations where you exhibited these traits. \n",
            "\n",
            "3. Use the STAR method: Structure your responses using the Situation, Task, Action and Result (STAR) method. Provide information about the Situation and the Task that you had to accomplish, describe the Action you took in that situation and then reveal the Result of your actions.\n",
            "\n",
            "4. Practice: Look up common behavioral questions and practice your responses. This will help you to feel prepared and confident when these questions come up.\n",
            "\n",
            "5. Develop good examples: Think of examples that show a range of behaviors, including team work, problem-solving ability, initiative, negotiation skills, organizational skills, etc. Make sure your examples demonstrate your skills and accomplishment.\n",
            "\n",
            "6. Be honest: Avoid fictionalizing or exaggerating your stories. Instead, be truthful and use real-life experiences to illustrate your points.\n",
            "\n",
            "7. Remember non-verbal communication: This is almost as important as your verbal communication. Make sure to maintain eye contact, use a firm handshake, sit up straight, and avoid nervous habits.\n",
            "\n",
            "8. Stay positive: Even when discussing difficult situations or mistakes, focus on what you learned and how you grew from the experience. \n",
            "\n",
            "9. Reflect on your past experiences: Choose examples from your past that are relevant to the job you're applying for and show how you would be the best fit.\n",
            "\n",
            "10. Show enthusiasm: Don't just tell your story, show them your passion and enthusiasm for the work you have done and your eagerness to bring this to your potential new role. \n",
            "\n",
            "Remember, preparation is key to acing a behavioral interview. Good luck!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations\n",
        "\n",
        "- The system role plays a critical role in shaping the assistant‚Äôs behavior, tone, and level of explanation.\n",
        "- Clearly defined roles result in more structured and context-aware responses.\n",
        "- The separation of concerns between the system message and user query improves prompt effectiveness.\n",
        "- Precise and well-scoped user questions lead to higher-quality outputs.\n",
        "- The exercise demonstrates how prompt design directly impacts response relevance and clarity.\n"
      ],
      "metadata": {
        "id": "XpOf6NgLbIa7"
      }
    }
  ]
}